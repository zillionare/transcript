#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•å­—å¹•å¯¹é½åŠŸèƒ½
"""

import os

# è®¾ç½®ç¦»çº¿æ¨¡å¼
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_HUB_OFFLINE"] = "1"

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    try:
        import whisperx
        print("âœ… WhisperX å¯¼å…¥æˆåŠŸ")
        
        model_dir = "/Volumes/share/data/models/huggingface/hub"
        device = "cpu"
        
        print("æ­£åœ¨åŠ è½½å¯¹é½æ¨¡å‹...")
        
        # å°è¯•ä½¿ç”¨æœ¬åœ°è·¯å¾„
        from pathlib import Path
        local_model_path = Path(model_dir) / "models--jonatasgrosman--wav2vec2-large-xlsr-53-chinese-zh-cn"
        if local_model_path.exists():
            # æŸ¥æ‰¾æœ€æ–°çš„å¿«ç…§ç›®å½•
            snapshots_dir = local_model_path / "snapshots"
            if snapshots_dir.exists():
                snapshot_dirs = [d for d in snapshots_dir.iterdir() if d.is_dir()]
                if snapshot_dirs:
                    latest_snapshot = max(snapshot_dirs, key=lambda x: x.stat().st_mtime)
                    print(f"ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {latest_snapshot}")
                    model_name = str(latest_snapshot)
                else:
                    model_name = "jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn"
            else:
                model_name = "jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn"
        else:
            model_name = "jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn"
        
        model_a, metadata = whisperx.load_align_model(
            language_code="zh", 
            device=device, 
            model_name=model_name, 
            model_dir=model_dir
        )
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"æ¨¡å‹ç±»å‹: {type(model_a)}")
        print(f"è¯­è¨€: {metadata['language']}")
        print(f"å­—å…¸å¤§å°: {len(metadata['dictionary'])}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("=== ç®€å•æ¨¡å‹åŠ è½½æµ‹è¯• ===\n")
    
    if test_model_loading():
        print("\nğŸ‰ æµ‹è¯•æˆåŠŸ! å­—å¹•å¯¹é½åŠŸèƒ½å·²å‡†å¤‡å°±ç»ª")
        print("\nç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è¿›è¡Œå­—å¹•å¯¹é½:")
        print("1. ä½¿ç”¨ transcript.py çš„ merge å‘½ä»¤")
        print("2. ç›´æ¥è°ƒç”¨ align_subtitles_with_audio å‡½æ•°")
        print("\næ¨¡å‹å·²æ­£ç¡®é…ç½®ï¼Œå¯ä»¥ç¦»çº¿ä½¿ç”¨!")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")
